{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "import io \n",
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import widgets, Layout, HBox\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"val_dataset_128.npy\"\n",
    "dataset = np.load(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c09b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arr(arr, hide_axis=False, norm = False):\n",
    "    if norm:\n",
    "        # Normalize the array values to the range [-1, 1]\n",
    "        arr = arr / np.max(np.abs(arr))\n",
    "    # Create a custom colormap that goes from blue (negative) to white (zero) to red (positive)\n",
    "    cmap = plt.cm.bwr\n",
    "    v_min = np.min([np.min(arr),-1])\n",
    "    v_max = np.max([np.max(arr),1])\n",
    "    plt.imshow(arr, cmap=cmap, interpolation='nearest', vmin=v_min, vmax=v_max)\n",
    "    if hide_axis:\n",
    "        plt.axis('off')\n",
    "    plt.colorbar()  # Add a colorbar to show the scale\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb5ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_norm(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55262e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_index(reference_dose, evaluated_dose, distance_criterion=3, dose_criterion=0.03, pixel_spacing=2.72):\n",
    "    \"\"\"\n",
    "    Calculate the chi index between two 2D dose distributions using the Bakai method.\n",
    "\n",
    "    Args:\n",
    "        reference_dose (np.array): 2D numpy array of the reference dose distribution (shape: 128x128x1)\n",
    "        evaluated_dose (np.array): 2D numpy array of the evaluated dose distribution (shape: 128x128x1)\n",
    "        distance_criterion (int): Distance criterion (in mm)\n",
    "        dose_criterion (float): Dose criterion (in the same unit as the dose distributions)\n",
    "        pixel_spacing (float): Pixel spacing (in mm) representing the distance between pixels (default: 2.72)\n",
    "\n",
    "    Returns:\n",
    "        chi_map (np.array): 2D numpy array of chi indices\n",
    "    \"\"\"\n",
    "    # Ensure the arrays have the same shape\n",
    "    assert reference_dose.shape == evaluated_dose.shape, \"Reference and evaluated dose arrays must have the same shape.\"\n",
    "    assert reference_dose.shape[2] == 1 and evaluated_dose.shape[2] == 1, \"Input arrays should have a shape of 128x128x1.\"\n",
    "\n",
    "    # Squeeze the arrays to remove the extra dimension\n",
    "    reference_dose = vec_norm(np.squeeze(reference_dose))\n",
    "    evaluated_dose = vec_norm(np.squeeze(evaluated_dose))\n",
    "    \n",
    "    \n",
    "    delta_r = (distance_criterion / pixel_spacing)\n",
    "    if np.max(reference_dose)==0:\n",
    "        return np.expand_dims(evaluated_dose/delta_r, axis=2)\n",
    "\n",
    "    dose_difference = evaluated_dose - reference_dose\n",
    "\n",
    "    # Calculate the gradient of the reference dose distribution\n",
    "    gradient_y, gradient_x = np.gradient(reference_dose, pixel_spacing)\n",
    "    gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "    delta_r = (distance_criterion / pixel_spacing)\n",
    "\n",
    "\n",
    "    chi_map = dose_difference / np.sqrt(   delta_r**2 + (dose_criterion**2) * gradient_magnitude)\n",
    "    return np.expand_dims(chi_map, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"finetuned_ConvLSTM_Model_128_dice_10.h5\"\n",
    "\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path, compile=False)\n",
    "bce_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loaded_model.compile(loss=bce_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c81e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def threshold_array(arr, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Set array values between 0 and 1 to 0 or 1 based on a threshold.\n",
    "\n",
    "    Parameters:\n",
    "        arr (np.array): Input array.\n",
    "        threshold (float): Threshold value between 0 and 1 to decide whether to set values to 0 or 1.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Modified array where values between 0 and 1 are set to 0 if below threshold and 1 if above.\n",
    "    \"\"\"\n",
    "    # Ensuring the threshold is within the valid range\n",
    "    if not (0 <= threshold <= 1):\n",
    "        raise ValueError(\"Threshold must be between 0 and 1\")\n",
    "\n",
    "    # Apply threshold to values between 0 and 1\n",
    "    arr[(arr > 0) & (arr < 1)] = (arr[(arr > 0) & (arr < 1)] >= threshold).astype(int)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa10f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_bbox(mask, dilation=0):\n",
    "    three_dim=False\n",
    "    \n",
    "    if len(mask.shape)==3:\n",
    "        three_dim = True\n",
    "        mask = np.squeeze(mask)\n",
    "    rows, cols = np.nonzero(mask)\n",
    "    \n",
    "    if len(rows) == 0 or len(cols) == 0:\n",
    "        return mask\n",
    "\n",
    "    min_row, max_row = np.min(rows), np.max(rows)\n",
    "    min_col, max_col = np.min(cols), np.max(cols)\n",
    "\n",
    "    min_row = max(0, min_row - dilation)\n",
    "    max_row = min(mask.shape[0] - 1, max_row + dilation)\n",
    "    min_col = max(0, min_col - dilation)\n",
    "    max_col = min(mask.shape[1] - 1, max_col + dilation)\n",
    "\n",
    "    bbox = np.zeros_like(mask)\n",
    "\n",
    "\n",
    "    bbox[min_row:max_row+1, min_col:max_col+1] = 1\n",
    "    \n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def ROI_passrate(D_R,D_E,ROI_type='union', dose_criterion=0.03):\n",
    "    if ROI_type=='union':\n",
    "        ROI = np.logical_or(D_R,D_E)\n",
    "    elif ROI_type=='union_bb':\n",
    "        ROI = np.expand_dims(mask_to_bbox(np.squeeze(np.logical_or(D_R,D_E)), dilation=int(0.005 * D_R.shape[0])),axis=-1)\n",
    "    elif ROI_type=='whole':\n",
    "        ROI = np.ones((128,128,1), dtype=bool)\n",
    "    else:\n",
    "        raise Exception(\"Unknown ROI type\")\n",
    "    ROI_chi_map = chi_index(D_R, D_E)[ROI]\n",
    "    \n",
    "    if ROI_chi_map.shape!=(0,):\n",
    "        pass_rate = (np.abs(ROI_chi_map)<dose_criterion).sum() / ROI.sum()\n",
    "        return pass_rate\n",
    "    #both masks are black:\n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2979330",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_frame_alg_pass = []\n",
    "whole_frame_avg_pass = []\n",
    "whole_frame_blk_pass = []\n",
    "\n",
    "union_bb_alg_pass = []\n",
    "union_bb_avg_pass = []\n",
    "union_bb_blk_pass = []\n",
    "\n",
    "\n",
    "union_only_alg_pass = []\n",
    "union_only_avg_pass = []\n",
    "union_only_blk_pass = []\n",
    "\n",
    "\n",
    "\n",
    "for idx in range(len(dataset)):\n",
    "    example = dataset[idx]\n",
    "\n",
    "    frames = example[:19, ...]\n",
    "    ground_truth_frame = example[19, ...]\n",
    "\n",
    "    new_prediction = loaded_model.predict(np.expand_dims(frames, axis=0))\n",
    "    new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "    predicted_20th_frame = new_prediction[-1, ...]\n",
    "\n",
    "    cd = ground_truth_frame\n",
    "    md = predicted_20th_frame\n",
    "    count = (np.abs(chi_index(cd,md)) < 0.03).sum()\n",
    "\n",
    "\n",
    "    avg_d = np.expand_dims(np.squeeze(np.mean(frames,axis=0)), axis=-1)\n",
    "    blk_d = np.zeros(cd.shape)\n",
    "    count_avg = (np.abs(chi_index(cd,avg_d)) < 0.03).sum()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    # Ground truth\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(np.squeeze(ground_truth_frame), cmap=\"gray\")\n",
    "    plt.title(f\"Ground Truth (Frame 20) of {idx}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Predicted\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(np.squeeze(predicted_20th_frame), cmap=\"gray\")\n",
    "    plt.title(f\"Predi (Frame 20) of {idx}\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    \n",
    "    # average\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(np.squeeze(avg_d), cmap=\"gray\")\n",
    "    plt.title(f\"Avg of 19 frames of {idx}\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "\n",
    "    # black\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(np.squeeze(blk_d), cmap=\"gray\")\n",
    "    plt.title(f\"Black frame\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    whole_frame_alg_pass.append(ROI_passrate(cd,md,ROI_type='whole'))\n",
    "    whole_frame_avg_pass.append(ROI_passrate(cd,avg_d,ROI_type='whole'))\n",
    "    whole_frame_blk_pass.append(ROI_passrate(cd,blk_d,ROI_type='whole'))\n",
    "\n",
    "    union_bb_alg_pass.append(ROI_passrate(cd,md,ROI_type='union_bb'))\n",
    "    union_bb_avg_pass.append(ROI_passrate(cd,avg_d,ROI_type='union_bb'))\n",
    "    union_bb_blk_pass.append(ROI_passrate(cd,blk_d,ROI_type='union_bb'))\n",
    "\n",
    "\n",
    "    union_only_alg_pass.append(ROI_passrate(cd,md,ROI_type='union'))\n",
    "    union_only_avg_pass.append(ROI_passrate(cd,avg_d,ROI_type='union'))\n",
    "    union_only_blk_pass.append(ROI_passrate(cd,blk_d,ROI_type='union'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a82be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(whole_frame_alg_pass))\n",
    "print(np.mean(whole_frame_avg_pass))\n",
    "print(np.mean(whole_frame_blk_pass))\n",
    "\n",
    "print(np.mean(union_bb_alg_pass))\n",
    "print(np.mean(union_bb_avg_pass))\n",
    "print(np.mean(union_bb_blk_pass))\n",
    "\n",
    "\n",
    "print(np.mean(union_only_alg_pass))\n",
    "print(np.mean(union_only_avg_pass))\n",
    "print(np.mean(union_only_blk_pass))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a40ed24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
