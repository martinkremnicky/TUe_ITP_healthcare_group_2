{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717f6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3e2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e975be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConvBlock(nn.Module):\n",
    "    \"\"\" Convolutional block for U-Net architecture.\n",
    "        \n",
    "        Block consists of two convolutional 2d layers, followed by batch normalization, ReLu activation \n",
    "        and a Drop Out layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size = 3): \n",
    "        \"\"\" Initializes double_conv_block with specified input and output channels,\n",
    "                kernel size, and padding.\n",
    "        \"\"\"\n",
    "        super(DoubleConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Dropout(0.4),\n",
    "                            nn.Conv2d(out_channels, out_channels, kernel_size, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Dropout(0.4)\n",
    "                            )\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.conv(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder architecture.\n",
    "        \n",
    "        It consists of several convolutional blocks with max pooling layers.\n",
    "\n",
    "    Args:\n",
    "        channels (List[int]): A list of channels for the convolutional block.\n",
    "        \n",
    "    Example:\n",
    "        channels = [1, 64, 128, 256, 512]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoderBlocks = nn.ModuleList()\n",
    "\n",
    "        # Adds a convolutional block followed by a max pooling layer (except the last one)\n",
    "        for i in range(len(channels)-1):\n",
    "            self.encoderBlocks.append(\n",
    "                DoubleConvBlock(channels[i], channels[i+1])),\n",
    "\n",
    "            if i < len(channels)-2:\n",
    "                self.encoderBlocks.append(nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        features_encoder = []\n",
    "        for encoder_block in self.encoderBlocks:\n",
    "            x = encoder_block(x)\n",
    "\n",
    "            # Save output of each convolutional block\n",
    "            if isinstance(encoder_block, DoubleConvBlock):\n",
    "                encoder_features.append(x)\n",
    "\n",
    "        return features_encoder\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder architecture\n",
    "\n",
    "        It consists of several convolutional blocks with decreasing number of channels\n",
    "\n",
    "    Args:\n",
    "        channels (List[int]): A list of channels for convolutionals block\n",
    "    \n",
    "    Example:\n",
    "        channels = [512, 256, 128, 64]\n",
    "                                            \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels): \n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoderBlocks = nn.ModuleList()\n",
    "\n",
    "        # Add a upconvolutional followed by a double convolutional block for each level\n",
    "        for i in range(len(channels)-1):\n",
    "            self.decoderBlocks.append(nn.ConvTranspose2d(\n",
    "                channels[i], channels[i+1], 2, 2))\n",
    "            self.decoderBlocks.append(\n",
    "                DoubleConvBlock(channels[i], channels[i+1]))\n",
    "\n",
    "    def _center_crop(self, feature, target_size): \n",
    "        \"\"\"Crops the input tensor to the target size.\n",
    "        \n",
    "        Args:\n",
    "            feature (torch.Tensor)\n",
    "            target_size (torch.Tensor)\n",
    "            \n",
    "        Returns: \n",
    "            cropped feature (torch.Tensor)\n",
    "        \"\"\"\n",
    "        _, _, H, W = target_size.shape\n",
    "        _, _, h, w = feature.shape\n",
    "\n",
    "        # Calculate the starting indices for the crop\n",
    "        h_start = (h - H) // 2\n",
    "        w_start = (w - W) // 2\n",
    "\n",
    "        # Crop and returns the tensor\n",
    "        return feature[:, :, h_start:h_start+H, w_start:w_start+W]\n",
    "\n",
    "    def forward(self, x, features_encoder): #-> torch.Tensor:\n",
    "\n",
    "        for i, decoder_block in enumerate(self.decoderBlocks):\n",
    "\n",
    "            # Concatenate the output of the encoder with the output of the decoder\n",
    "            if isinstance(decoder_block, DoubleConvBlock):\n",
    "                features_encoder = self._center_crop(features_encoder[i//2], x)\n",
    "                x = torch.cat([x, features_encoder], dim=1)\n",
    "\n",
    "            # Apply the upconv or double convolutional block\n",
    "            x = decoder_block(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"The UNet architecture.   \n",
    "\n",
    "    Args:\n",
    "        out_channels (int): The number of output channels.\n",
    "        channels (List[int]): A list of channels for convolutionals block.\n",
    "\n",
    "    Example:\n",
    "        model = UNet(channels=[1, 64, 128, 256, 512], out_channels=1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, out_channels): \n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = Encoder(channels)\n",
    "        self.decoder = Decoder(channels[::-1][:-1])\n",
    "        self.output = nn.Conv2d(channels[1], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x): \n",
    "        features_encoder = self.encoder(x)[::-1]\n",
    "        x = self.decoder(features_encoder[0], features_encoder[1:])\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e1c646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "201e3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMRI(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, augment = False, patch_size = 256):\n",
    "        super(DatasetMRI, self).__init__()\n",
    "        \n",
    "        # Train and test csv file\n",
    "        self.csv_file = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.augment = augment\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # Get folder name at specified index\n",
    "        folder_name = self.csv_file.iloc[index]['id']\n",
    "        # Get the filename at the specified index\n",
    "        filename_img = self.csv_file.iloc[index][\"p_id\"]\n",
    "        filename_seg = self.csv_file.iloc[index][\"p_id_seg\"]\n",
    "        \n",
    "        # Full path to the image file\n",
    "        image_path = os.path.join(self.root_dir, folder_name, filename_img)\n",
    "        segmentation_path = os.path.join(self.root_dir, folder_name, filename_seg)\n",
    "        \n",
    "        # MRI scan\n",
    "        image = self.read_nifti(image_path)\n",
    "        # Segmentation\n",
    "        seg = self.read_nifti(segmentation_path)\n",
    "\n",
    "        # Get biggest tumor slice \n",
    "        biggest_img, biggest_seg = self.get_slice(image, seg)\n",
    "        norm_img = self.normalize(biggest_img)\n",
    "    \n",
    "        # Add channel dimension and convert to tensor\n",
    "        image_tensor = torch.from_numpy(norm_img).unsqueeze(0).float()  \n",
    "        seg_tensor = torch.from_numpy(biggest_seg).unsqueeze(0).float()\n",
    "\n",
    "        image_tensor = self.partition(image_tensor, self.patch_size)\n",
    "        seg_tensor = self.partition(seg_tensor, self.patch_size)\n",
    "        \n",
    "        if self.augment:\n",
    "            image_tensor = [self.apply_augmentation(chunk) for chunk in image_tensor]\n",
    "\n",
    "        image_tensor = torch.stack(image_tensor)\n",
    "        seg_tensor = torch.stack(seg_tensor)\n",
    "        \n",
    "        return image_tensor, seg_tensor\n",
    "    \n",
    "    def read_nifti(self, filepath):\n",
    "        \"\"\"Read a NIfTI file.\n",
    "    \n",
    "            Args:\n",
    "                filepath (str): Path to the NIfTI file.\n",
    "            Returns:\n",
    "                image (numpy array)\n",
    "        \"\"\"\n",
    "        # Load NIfTI file\n",
    "        img = nib.load(filepath)\n",
    "        # Get the image data as a numpy array\n",
    "        img_data = img.get_fdata()\n",
    "\n",
    "        return img_data\n",
    "    \n",
    "    def partition(self, image, patch_size):\n",
    "        \"\"\"Partition the images into patch_size squares\n",
    "        Args:\n",
    "            image (Tensor): MRI images\n",
    "            patch_size (int): size of the division of images\n",
    "        \n",
    "        Returns:\n",
    "            patches (List): list of the different divisions of the image\n",
    "        \n",
    "        \"\"\"\n",
    "        patches = []\n",
    "        _, height, width = image.shape\n",
    "        for i in range(0, height, patch_size):\n",
    "            for j in range(0, width, patch_size):\n",
    "                patch = image[:, i:i+patch_size, j:j+patch_size]\n",
    "                # Padding if the patch is smaller than patch_size\n",
    "                if patch.shape[1] < patch_size or patch.shape[2] < patch_size:\n",
    "                    pad = torch.nn.functional.pad(patch, (0, patch_size-patch.shape[2], 0, patch_size-patch.shape[1]), 'constant', 0)\n",
    "                    patches.append(pad)\n",
    "                else:\n",
    "                    patches.append(patch)\n",
    "        return patches\n",
    "    \n",
    "    def get_slice(self, image, seg):\n",
    "        \"\"\"Choose the slice where the biggest tumour map is\n",
    "\n",
    "        Args:\n",
    "            image (tensor): MRI image\n",
    "            seg (tensor): segmentation map\n",
    "        \n",
    "        Returns:\n",
    "            biggest_img (array): corresponds to biggest slice from image\n",
    "            biggest_seg (array): corresponds to biggest slice from segmentation map\n",
    "        \"\"\"\n",
    "        \n",
    "        max_area = 0\n",
    "        idx_slice = 0\n",
    "\n",
    "        for i in range(seg.shape[2]):\n",
    "            slice = seg[:, :, i]\n",
    "            # Calculate the area of the tumor in the current slice\n",
    "            tumor_area = np.sum(slice)\n",
    "            # Update the maximum area and slice index if the current slice has a larger area\n",
    "            if tumor_area > max_area:\n",
    "                max_area = tumor_area\n",
    "                idx_slice = i\n",
    "        \n",
    "        # Get biggest slice\n",
    "        biggest_img = image[:,:,idx_slice]\n",
    "        biggest_slice = seg[:,:,idx_slice]\n",
    "        \n",
    "        return biggest_img, biggest_slice\n",
    "    \n",
    "    def normalize(self, image):\n",
    "        \"\"\"Normalize the image using mean and standard deviation.\n",
    "\n",
    "        Args:\n",
    "            image (numpy.ndarray): The image to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: The normalized image.\n",
    "        \"\"\"\n",
    "        min_val = np.min(image)\n",
    "        max_val = np.max(image)\n",
    "\n",
    "        normalized_image = image - min_val\n",
    "        normalized_image = image / (max_val - min_val)\n",
    "        \n",
    "        return normalized_image\n",
    "\n",
    "        \n",
    "    def apply_augmentation(self, image_tensor):\n",
    "        \"\"\"Applies blur imitating motion blur in a image\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply random Gaussian blur\n",
    "        if random.random() > 0.5:\n",
    "            blur_transform = transforms.GaussianBlur(kernel_size=(5, 9), sigma=(2, 5))\n",
    "            image_tensor = blur_transform(image_tensor)\n",
    "        \n",
    "        return image_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f3a88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validation and test dataloaders from an already split dataset\n",
    "\n",
    "batch_size = 5\n",
    "rootdir = os.path.abspath('data_images')\n",
    "\n",
    "mri_dataset = DatasetMRI(csv_file=os.path.abspath('training.csv'),root_dir=rootdir, augment = True, patch_size = 256)\n",
    "train_loader = DataLoader(mri_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = DatasetMRI(csv_file=os.path.abspath('validation.csv'),root_dir=rootdir, augment = False, patch_size = 256)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = DatasetMRI(csv_file=os.path.abspath('test.csv'), root_dir = rootdir, augment = False, patch_size = 256)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 5 samples from train_loader\n",
    "num_samples = 5\n",
    "count = 0\n",
    "\n",
    "for i,(imgs,lbs) in enumerate(train_loader):\n",
    "    for j in range(len(imgs)):\n",
    "        if count > num_samples:\n",
    "            break\n",
    "        plt.figure()\n",
    "        plt.imshow(imgs[j][1,0,:,:],cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(lbs[j][1,0,:,:],cmap='gray')\n",
    "        plt.show()\n",
    "        count+=1\n",
    "    if count >= num_samples:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37243b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(channels=[1, 64, 128, 256, 512, 1024], out_channels=1).to(device)\n",
    "criterion = DiceLoss()  # Adjust the loss function as per your task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = np.inf\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for image, true_mask in train_loader:\n",
    "        partition_loss = 0.0\n",
    "        for partition in range(image.shape[1]):\n",
    "            images, masks = image[partition,:,:,:].to(device), true_mask[partition,:,:,:].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            partition_loss += loss.item()\n",
    "            \n",
    "        train_loss += partition_loss\n",
    "        train_loss /= len(image)\n",
    "\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_loader:\n",
    "            partition_val_loss = 0.0\n",
    "            for partition in range(images.shape[1]):\n",
    "\n",
    "                images, masks = image[partition,:,:,:].to(device), true_mask[partition,:,:,:].to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                partition_val_loss += loss.item()\n",
    "                \n",
    "            val_loss += partition_val_loss\n",
    "            val_loss /= len(images)\n",
    "                \n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f\"models_unet/unet_model_{epoch}_{timestamp}.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "613c4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'unet_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test predictions\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(channels=[1, 64, 128, 256, 512, 1024], out_channels=1).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (images, masks) in enumerate(test_loader):\n",
    "        for partition in range(images.shape[1]):\n",
    "            image, mask = images[partition,:, :, :].to(device), masks[partition, :, :, :].to(device)\n",
    "            outputs = model(image)\n",
    "\n",
    "            for batch in range(image.shape[0]):\n",
    "                img = image[batch].cpu().numpy().squeeze()\n",
    "                msk = mask[batch].cpu().numpy().squeeze()\n",
    "                output = torch.sigmoid(outputs[batch]).cpu().numpy().squeeze()\n",
    "                # Binarize the output for visualization\n",
    "                output = (output > 0.5).astype(np.uint8)\n",
    "\n",
    "                # Plot the original image, true mask, and predicted mask\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                axes[0].imshow(img, cmap='gray')\n",
    "                axes[0].set_title('Original Image')\n",
    "                axes[0].axis('off')\n",
    "\n",
    "                axes[1].imshow(msk, cmap='gray')\n",
    "                axes[1].set_title('Ground truth')\n",
    "                axes[1].axis('off')\n",
    "\n",
    "                axes[2].imshow(output, cmap='gray')\n",
    "                axes[2].set_title('Predicted segmentation')\n",
    "                axes[2].axis('off')\n",
    "\n",
    "                plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
